<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
	<head>
	
		<title>Readability Test Results</title>

		<meta name="viewport" content="width=650,user-scalable=true" />
		<meta name="robots" content="noindex,nofollow" />
		<meta name="ua" content="curl/7.39.0 Rcurl/1.95.4.5 httr/0.6.1" />

		<link type="text/css"  href="http://fonts.googleapis.com/css?family=Rokkitt:400,700" rel="stylesheet" />
		<link type="text/css" href="./css/screen.css" rel="stylesheet" media="screen" />
		<link type="text/css" href="./css/ui.all.css" rel="stylesheet" />

		<script type="text/javascript" src="./js/jquery-1.3.1.min.js"></script>
		<script type="text/javascript" src="./js/jquery.ui.all.js"></script>
		<script type="text/javascript" src="./js/behaviours.js"></script>
		
	</head>
	<body>


		<div id="header">
			<div id="bookmarklet"><a href="bookmarklet.html">Readability Test Bookmarklet</a></div>
			<h1>
				<a href="./"><span>The Readability Test Tool</span></a>
			</h1>
			<p>Let's make the unreadable readable</p>		
		</div>

		<div id="content">
		
<h2>Readability Test Results</h2>




<p class="meanScore scale-d">
	This page has an average <a href="http://en.wikipedia.org/wiki/U.S._grade_level#School_grades">grade level</a> of about 8.<br/><br/>
	It should be easily understood by 13 to 14 year olds.</p>

<p><a href="http://twitter.com/home?status=My+page+has+grade+level+of+%7E8+and+should+be+understood+by+13-14+year+olds+http%3A%2F%2Fwww.read-able.com%2F+%23readability">Tweet this result!</a></p>

<!--
<div class="readabilityText"><pre style="max-height: 200px;">
	        			Posted by 
	        				Simon Munzert on January 19, 2015
	        			
	        		
A considerable share of Twitter accounts is not actually run by humans. According to a recent release by Twitter, `up to approximately 8.5%' of the active users are bots or third-party software that automatically aggregates tweets. Bots can follow other users, retweet content or post content on their own. What they say is essentially generated by scripts. 
Take @TwoHeadlines, for example. The bot, hosted by Darius Kazemi, scrapes headlines from Google News and replaces one of the nouns with another trending noun, which generates hilarious and sometimes thought-provoking tweets. Twitter bots can be more than just gadgets for nerds: A notable example is the congress-edits bot that tracks and posts modifications on Wikipedia which are made from IP addresses located inside the US Congress. It is fascinating to see how programmers use their creativity to repurpose Twitter's range and popularity.
If you are familiar with R, such projects are well within your reach. In this post, I give a little demonstration of how to program your own Twitter bot using R. The goal is to create a nerve-racking bot that reminds PhD students of their primary duty, that is to work on the dissertation. You can check out the results here.
The PhD whipping bot is inspired by @indiewhipbot, an equally tedious contemporary who pushes indie game developers back to work by shouting orders and closing with a mild insult. For my bot, I start by setting up three little databases stored in XLS sheets. You can find all of them at the end of this post. The first stores (de-)motivating phrases:
The second and third database contain a list of animal names that were scraped from Wikipedia and a short list of negative attributes:
I use them to add some random mockery to the bot's shoutings. Pasting it together into one random tweet (everything in capital letters for an extra pinch of annoyance) works as follows:
Motivating, indeed. 
In order to tweet these random whiplashes using R, we first register a new app on apps.twitter.com for OAuth credentials, which we then use to log onto our Twitter account with R using the twitteR package. We have elaborated on this procedure in more detail in a previous post. In short, we load the twitteR package and connect to Twitter's REST API via OAuth, using credentials previously stored in the environment, that is the .Renviron file stored in your home directory which you can locate by entering normalizePath("~/") in the console:
Now, we can let the bot tweet a random entry with the tweet() function:
Naturally, it would be cumbersome if we had to operate the bot manually. Fortunately, there are means to execute an R script on a regular basis without manual input. As I happen to use a Windows machine as running server, I demonstrate how to schedule R tasks in Windows. We illustrate how to do this on a Linux/Mac OS machine in our book.
On Windows platforms, the Windows Task Scheduler is the native tool for scheduling tasks. You'll find the Scheduler (on Windows 8) by right-clicking on Start > Computer Management > Task Scheduler. To set up a new task, click on Create Task. We are presented with a window with five tabs – General, Triggers, Actions, Conditions, and Settings. Under General we can provide a name for the task. Here I insert R PhD Whipping Bot for a descriptive title. In the field Triggers, we can add several triggers for starting the task. There are schedule triggers which start the task every day, week, or month and also triggers that refer to events like the startup of the computer or when it is in idle mode, and many more. After having set an execution interval, we should make sure that the start date and time of our task is placed in the future when we are done specifying the schedule. 
Next, we have to tell the Scheduler what to execute at the specified time. This is defined in the Actions tab. We choose Start a program for action and use the browse button to select the destination of Rscript.exe, which should be placed under, e.g., C:\Program Files\R\R-3.1.2\bin\x64\. Next, we add phdwhipbot.r in the Add arguments field and type in the directory where the script is placed in the Start in field. 
If you want to log all bot tweets in one common file, you can do so by adding the following to the script:
Done! I hope this little bot helps you to stay on track. You can find the full R script as well as the related data here.
P.S.: I recently discovered the Bot Weekly newsletter, a wonderful entry point into bot-land.
P.P.S.: If you've created your own Twitter bot with R, I'd love to hear about it! Feel free to share them with me. Or me. COWARDLY ELK. 
Copyright © The Authors 2015
</pre></div>
-->




<h3>Readability Indices</h3>
<table>
	<tr>
		<th>Flesch Kincaid Reading Ease</th>
		<td>67.1</td>
		<td class="indicator"><div class="scale scale-d"></div></td>
	</tr>
	<tr>
		<th>Flesch Kincaid Grade Level</th>
		<td>7.4</td>
		<td class="indicator"><div class="scale scale-d"></div></td>
	</tr>
	<tr>
		<th>Gunning Fog Score</th>
		<td>9.7</td>
		<td class="indicator"><div class="scale scale-c"></div></td>
	</tr>
	<tr>
		<th>SMOG Index</th>
		<td>7.7</td>
		<td class="indicator"><div class="scale scale-d"></div></td>
	</tr>	
	<tr>
		<th>Coleman Liau Index</th>
		<td>10.2</td>
		<td class="indicator"><div class="scale scale-c"></div></td>
	</tr>
	<tr>
		<th>Automated Readability Index</th>
		<td>6.4</td>
		<td class="indicator"><div class="scale scale-d"></div></td>
	</tr>	
</table>	


<h3>Text Statistics</h3>	


<table>
	<tr>
		<th>No. of sentences</th>
		<td>60</td>
		<td class="indicator"></td></td>
	</tr>	
	<tr>
		<th>No. of words</th>
		<td>840</td>
		<td></td>
	</tr>
	
	<tr>
		<th>No. of complex words</th>
		<td>104</td>
		<td></td>
	</tr>
	
	<tr>
		<th>Percent of complex words</th>
		<td>12.38%</td>
		<td></td>
	</tr>
	<tr>
		<th>Average words  per sentence</th>
		<td>14.00</td>
		<td></td>
	</tr>	
	<tr>
		<th>Average syllables per word</th>
		<td>1.48</td>
		<td></td>
	</tr>	
</table>	




			
			<div id="whatItDoes" class="clear">
				<h2>What do these results mean?</h2>
				
				<p>The indicator bars give a visual guide for the readability of the text. Red is a low readability score.  Green is easily readable.</p>
				
								
				<h3>Flesch Kincaid Reading Ease</h3>
				
				<p>Based on a 0-100 scale. A high score means the text is easier to read.  Low scores suggest the text is complicated to understand.</p>

				<code>206.835 - 1.015 x (words/sentences) - 84.6 x (syllables/words)</code>
				
				<p>A value between 60 and 80 should be easy for a 12 to 15 year old to understand.</p> 
				
				
				
				<h3>Grade Level indicators</h3>
				
				<p>These equate the readability of the text to the US schools grade level system.</p>
				
				
				<h3>Flesch Kincaid Grade Level</h3>
				
				<code>0.39 x (words/sentences) + 11.8 x (syllables/words) - 15.59</code>
				
				
				
				<h4>Gunning Fog Score</h4>
				
				<code>0.4 x ( (words/sentences) + 100 x (complexWords/words) )</code>
				
				
				<h4><acronym title="Simple Measure of Gobbledygook">SMOG</acronym> Index</h4>
				
				<code>1.0430 x sqrt( 30 x complexWords/sentences ) + 3.1291</code>
				
				
				<h4>Coleman Liau Index</h4>
				
				<code>5.89 x (characters/words) - 0.3 x (sentences/words) - 15.8</code>
				
				
				<h4>Automated Readability Index (ARI)</h4>
				
				<code>4.71 x (characters/words) + 0.5 x (words/sentences) - 21.43</code>
				
				<p>Coleman Liau and ARI rely on counting characters, words and sentence. The other indices consider number of syllables and complex words (polysyllabics - with 3 or more syllables) too.  Opinions vary on which type are the most accurate.  It is more difficult to automate the counting of syllable as the English language does not comply to strict standards!  </p>

			</div>







	
				
		</div><!--#content-->
		
		
		<div id="footer">	
			<div>
				Copyright &copy; 2009-2014 <a href="http://davidsimpson.me/">David Simpson</a>. 
				All rights reserved.
			</div>

			<ul>
				<li class="first"><a href="/privacy-policy.html">Privacy Policy</a></li>
				<li><a href="/terms-of-service.html">Terms of Service</a></li>
				<li><a href="/press.html">Press</a></li>
				<li><a href="https://getsatisfaction.com/read-able/">Feedback</a></li>
				<li><a href="http://www.read-able.com/referer.php?id=content" title="Read Able. The Readability Test Tool">Readability Test</a></li>
			</ul>

			<p class="social">
				<a href="http://www.facebook.com/ReadabilityTestTool"><img src="images/32x32-facebook.png" title="We're on Facebook"/></a>
				<a href="http://www.twitter.com/readableapp"><img src="images/32x32-twitter.png" title="Follow us on Twitter"/></a>
			</p>
		</div><!--#footer-->




        <script>
                  
			location.getParameter = function(item){
				var svalue = location.search.match(new RegExp("[\?\&]" + item + "=([^\&]*)(\&?)","i"));
				return svalue ? svalue[1] : svalue;
			};

			//usage
			var mailchimpId = location.getParameter('mc_eid');
          
			(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
			(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
			m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
			})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

			if (mailchimpId === null) {
				ga('create', 'UA-920590-2', 'auto');
			} else {
				ga('create', 'UA-920590-2', {'userId': mailchimpId});
				ga('set', 'dimension1', mailchimpId); // also set a `customUserId` dimension at page level (for fun)
			}
			
			ga('require', 'displayfeatures');
			ga('send', 'pageview');

        </script>

	</body>
</html>



